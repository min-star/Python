## 2.9 评估、调参、优化人工神经网络

### K-折交叉验证（K-fold Cross Validation，记为K-CV）

- 将原始数据分成K组（一般是均分），将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，
- 这样会得到K个模型，用这K个模型最终的验证集的分类准确率的平均数作为此K-CV下分类器的性能指标。
- K一般大于等于2，实际操作时一般从3开始取，只有在原始数据集合数据量小的时候才会尝试取2。
+  应用最多，K-CV可以有效的避免过拟合与欠拟合的发生，最后得到的结果也比较具有说服性。

### keras中没有交叉验证功能，sklearn中提供了交叉验证的功能，因此需要将Keras分类器模型转换成 sklearn分类器模型，使用的就是：keras.wrappers.scikit_learn.KerasClassifier类


--------------------------------------------------------------------------------------------
## Dropout 记忆是建立模型的过程，忘记是优化模型的过程，见B站YJango学习观

- model.add(keras.layers.Dropout(rate=0.1))，rate 设置抛弃率。当rate > 0.5,这个模型容易出现欠拟合状态。
- 当rate = 0 时，即所有的神经网络都是健壮的，相当于人不会忘记。此时，模型容易出现过拟合状态。
--------------------------------------------------------------------------------------------
