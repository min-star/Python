## 2.9 评估、调参、优化人工神经网络

### K-折交叉验证（K-fold Cross Validation，记为K-CV）

- 将原始数据分成K组（一般是均分），将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，
- 这样会得到K个模型，用这K个模型最终的验证集的分类准确率的平均数作为此K-CV下分类器的性能指标。
- K一般大于等于2，实际操作时一般从3开始取，只有在原始数据集合数据量小的时候才会尝试取2。
+  应用最多，K-CV可以有效的避免过拟合与欠拟合的发生，最后得到的结果也比较具有说服性。

--------------------------------------------------------------------------------------------
